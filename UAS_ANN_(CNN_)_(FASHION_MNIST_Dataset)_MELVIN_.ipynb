{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UAS ANN (CNN ) (FASHION MNIST Dataset) MELVIN - 2301863263.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpJykHh3_o2I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b8c915a-4fda-4900-ada3-6e08a4f1e4cc"
      },
      "source": [
        "!pip install --upgrade tensorflow==1.15"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==1.15 in /usr/local/lib/python3.7/dist-packages (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.12.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.8.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.19.5)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.15.0)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.15.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.36.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (3.3.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.1.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.34.1)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.2.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.12.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.0.8)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (3.17.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15) (3.1.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (57.2.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.3.4)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (4.6.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow==1.15) (1.5.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.5.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ay1-U1BE_p4y"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import decomposition"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOiLRU7H_1G_",
        "outputId": "068afeaf-b020-47c5-f9dc-d583b6823193"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "print('X train:', x_train.shape)\n",
        "print('y train:', y_train.shape)\n",
        "print('X test:', x_test.shape)\n",
        "print('y test:', y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X train: (60000, 28, 28)\n",
            "y train: (60000,)\n",
            "X test: (10000, 28, 28)\n",
            "y test: (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWrTurd0Rc6n"
      },
      "source": [
        "**Pada code diatas saya langsung menload data fashion mnist dari tensorflow keras untuk langsung displit menjadi training set dan juga test set lengkap dengan x sebagai featurenya dan y sebagai labelnya atau indikasi kelasnya. Didapat bahwa shape atau bentuk data berukuran 2 dimensi dengan besar pixel sebesar 28 px x 28 px. Dengan data train sebesar 60.000 data dan data test sebesar 10.000 data**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "id": "JaDXn05iBwqq",
        "outputId": "a7cd0441-0b56-4cf8-cd9c-e7cd2a23e69e"
      },
      "source": [
        "plt.imshow(x_train[0], cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGn03PpaSGOr"
      },
      "source": [
        "**Diatas adalah contoh gambar sample yang diambil dari data \n",
        "paling pertama dari x train dimana dapat dilihat bahwa ukuran gambar 28 pixel x 28 pixel**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rF2phu-bCBb3",
        "outputId": "b64eaeca-2534-48be-8925-b46a2e139c6c"
      },
      "source": [
        "print(y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[9 0 0 ... 3 0 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkayBNVlSTws"
      },
      "source": [
        "**Ini adalah data label train yang dimunculkan yang berfungsi sebagai label klasifikasi dari kelas yang ada pada dataset tersebut dimana sebanyak 10 kelas (0-9).**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoeYQ1gzCCzQ"
      },
      "source": [
        "# Preprocess Label\n",
        "y_train = y_train.reshape([-1, 1])\n",
        "y_test = y_test.reshape([-1, 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eo4MSaJPSg4o"
      },
      "source": [
        "**Diatas label dipreprocess agar dimensinya dapat cocok dengan model yang ingin diisi atau ditrain**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKsk3PymCEUA",
        "outputId": "71a549ae-0bbf-49d6-cd87-8597325ce4b2"
      },
      "source": [
        "print(y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[9]\n",
            " [0]\n",
            " [0]\n",
            " ...\n",
            " [3]\n",
            " [0]\n",
            " [5]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sr2uyHGvS5sq"
      },
      "source": [
        "**Diatas adalah hasil dari label train yang sudah direshape**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLYEHoLmCHT7"
      },
      "source": [
        "encoder = OneHotEncoder(sparse=False)\n",
        "encoder.fit(y_train)\n",
        "y_train = encoder.transform(y_train)\n",
        "y_test = encoder.transform(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cjUAyMhCHzk",
        "outputId": "7a6429dd-ee78-445a-ce9e-e0512f0d7d7a"
      },
      "source": [
        "print(y_train[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwR15-NMCKB0"
      },
      "source": [
        "# Preprocess Image\n",
        "x_train = x_train.reshape([-1, 28, 28, 1])\n",
        "x_test = x_test.reshape([-1, 28, 28, 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYWcQvJSCKo4"
      },
      "source": [
        "# MinMaxScaler\n",
        "# 0 - 255 | 127.5\n",
        "# 0 - 1   | 0.5\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_e_drQYCMdi"
      },
      "source": [
        "input_placeholder = tf.placeholder(tf.float32, shape=[None, 28, 28, 1])\n",
        "label_placeholder = tf.placeholder(tf.float32, shape=[None, 10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdRrJ7PlTKyI"
      },
      "source": [
        "**Setelah semua data telah disiapkan atau di preprocess lalu placeholder atau tempat menampung datanya dibuat dimana disini saya membuat 2 placeholder yaitu untuk input atau x dan juga untuk labelnya atau y. Dimana dimensi input sebesar 28x28x1 yang melambangkan ukuran dari inputnya yaitu gamabar dengan 28 pixel x 28 pixel dan 1 untuk mewakili jumlah warna dimana dapat dilihat sebelumnya bahwa gambar yang ada pada dataset hanya memiliki 1 kombinasi warna yaitu greyscale atau hitam dan putih. Sedangkan untuk labelnya memiliki ukuran sebesar 10 yang mewakili jumlah class yang ada atau label yang ada yaitu 10 (0-9)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aCglZJICQDj"
      },
      "source": [
        "def dense(x, neuron_size, activation=None):\n",
        "  in_shape = x.shape[-1]\n",
        "\n",
        "  weight = tf.Variable(\n",
        "      tf.random.normal([in_shape, neuron_size])\n",
        "  )\n",
        "  bias = tf.Variable(\n",
        "      tf.random.normal([neuron_size])\n",
        "  )\n",
        "  out = tf.matmul(x, weight) + bias\n",
        "\n",
        "  if not activation: # Linear Activation\n",
        "    return out\n",
        "\n",
        "  return activation(out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HerS62Q1CRgB"
      },
      "source": [
        "def flatten(x):\n",
        "  res = 1\n",
        "  for s in x.shape[1:]:\n",
        "    res *= s\n",
        "\n",
        "  return tf.reshape(x, [-1, res])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62H_WAALCSqL"
      },
      "source": [
        "def conv2d(x, out_channels, kernel_size, strides=1, padding=\"SAME\", activation=tf.nn.relu): \n",
        "  in_channels = x.shape[-1]\n",
        "\n",
        "  kernel = tf.Variable(\n",
        "      tf.random.normal([kernel_size, kernel_size, in_channels, out_channels])\n",
        "  )\n",
        "  bias = tf.Variable(\n",
        "      tf.random.normal([out_channels])\n",
        "  )\n",
        "\n",
        "  out = tf.nn.conv2d(x, kernel, strides=strides, padding=padding) + bias\n",
        "\n",
        "  if not activation:\n",
        "    return out\n",
        "\n",
        "  return activation(out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEHw0WpmT_uo"
      },
      "source": [
        "**Diatas saya mendefinisikan sebuah function atau model Convolutional 2d dengan padding \"SAME\" karena input dan ouputnya nantinya akan memiliki dimensi yang sama. Setelah itu saya membuat function untuk kernel, bias, dan out dari model itu nantinya.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17Fr33mYCUOX",
        "outputId": "d2c2532f-7d12-4d1a-d591-b7f5534edc89"
      },
      "source": [
        "# Feed Forward\n",
        "out_conv1 = conv2d(input_placeholder, 8, 3, activation=tf.nn.relu)\n",
        "pooled1 = tf.nn.max_pool2d(out_conv1, 2, strides=2, padding=\"SAME\")\n",
        "\n",
        "out_conv2 = conv2d(pooled1, 16, 3, activation=tf.nn.relu)\n",
        "pooled2 = tf.nn.max_pool2d(out_conv2, 2, strides=2, padding=\"SAME\")\n",
        "\n",
        "flattened = flatten(pooled2)\n",
        "\n",
        "output_tensor = dense(flattened, 10)\n",
        "\n",
        "# logits : [0, 1, 0 , 0.5] (logits = output raw)\n",
        "# label : [1, 0, 0, 0]\n",
        "loss_tensor = tf.reduce_mean(\n",
        "    tf.nn.softmax_cross_entropy_with_logits(\n",
        "    logits = output_tensor,\n",
        "    labels = label_placeholder\n",
        "  )\n",
        ")\n",
        "\n",
        "train = tf.train.AdamOptimizer(0.01).minimize(loss_tensor)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-16-84ddc3886eb8>:17: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lHoGas6UZXh"
      },
      "source": [
        "**Lalu diatas dapat dilihat bahwa untuk training optimizernya saya menggunakan AdamOptimizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eishpshCWCI"
      },
      "source": [
        "# Batch training\n",
        "def get_batch(iteration, x, y, batch_size):\n",
        "  start_idx = iteration * batch_size\n",
        "  data_len = x.shape[0]\n",
        "\n",
        "  x_batch = x[start_idx: min(start_idx + batch_size, data_len)]\n",
        "  y_batch = y[start_idx: min(start_idx + batch_size, data_len)]\n",
        "  return x_batch, y_batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txbECntTCXRA"
      },
      "source": [
        "def accuracy_score(y_pred, y_true):\n",
        "  matches = tf.equal(\n",
        "      tf.argmax(y_pred, 1), \n",
        "      tf.argmax(y_true, 1) \n",
        "  )\n",
        "  return tf.reduce_mean(tf.cast(matches, tf.float32))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8HlLfmIUtW-"
      },
      "source": [
        "**Diatas saya membuat function untuk mencari angka akurasi yang nantinya akan berguna untuk terus mengeluarkan dan keep track pada angka akurasi untuk setiap epochnya nanti jika model sudah dijalankan**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGeTD1uTCYgN",
        "outputId": "fb60bfb1-1416-42ac-b830-6e394b46c5a6"
      },
      "source": [
        "num_epochs = 10\n",
        "batch_size = 520\n",
        "iter_len = x_train.shape[0] // batch_size # / bagi  // bagi abis itu floor\n",
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    print('')\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "    print('')\n",
        "    for iteration in range(iter_len):\n",
        "      x_batch, y_batch = get_batch(iteration, x_train, y_train, batch_size)\n",
        "      \n",
        "      train_dict = {\n",
        "          input_placeholder : x_batch,\n",
        "          label_placeholder : y_batch\n",
        "      }\n",
        "\n",
        "      sess.run(train, feed_dict = train_dict)\n",
        "\n",
        "      loss = sess.run(loss_tensor, feed_dict = train_dict)\n",
        "      acc = sess.run(accuracy_score(output_tensor, label_placeholder), feed_dict = train_dict)\n",
        "\n",
        "      if iteration % 20 == 0:\n",
        "        print(f'{iteration}/{iter_len} - loss : {loss:.4f} - acc : {acc:4f}')\n",
        "\n",
        "    test_dict = {\n",
        "        input_placeholder: x_test,\n",
        "        label_placeholder: y_test\n",
        "    }\n",
        "    val_loss = sess.run(loss_tensor, feed_dict = test_dict)\n",
        "    val_acc = sess.run(\n",
        "        accuracy_score(output_tensor, label_placeholder),\n",
        "        feed_dict = test_dict\n",
        "    )\n",
        "    print('====')\n",
        "    print('Validation Loss: ', val_loss)\n",
        "    print('Validation Acc: ', val_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1/10\n",
            "\n",
            "0/115 - loss : 328.6817 - acc : 0.159615\n",
            "20/115 - loss : 45.1006 - acc : 0.294231\n",
            "40/115 - loss : 16.3243 - acc : 0.534615\n",
            "60/115 - loss : 11.8285 - acc : 0.584615\n",
            "80/115 - loss : 9.3686 - acc : 0.626923\n",
            "100/115 - loss : 7.6628 - acc : 0.700000\n",
            "====\n",
            "Validation Loss:  7.1406264\n",
            "Validation Acc:  0.671\n",
            "\n",
            "Epoch 2/10\n",
            "\n",
            "0/115 - loss : 6.6681 - acc : 0.711538\n",
            "20/115 - loss : 6.0935 - acc : 0.694231\n",
            "40/115 - loss : 4.9741 - acc : 0.717308\n",
            "60/115 - loss : 4.1627 - acc : 0.732692\n",
            "80/115 - loss : 4.0801 - acc : 0.728846\n",
            "100/115 - loss : 4.1309 - acc : 0.736538\n",
            "====\n",
            "Validation Loss:  3.8814378\n",
            "Validation Acc:  0.7307\n",
            "\n",
            "Epoch 3/10\n",
            "\n",
            "0/115 - loss : 3.3343 - acc : 0.755769\n",
            "20/115 - loss : 3.3690 - acc : 0.736538\n",
            "40/115 - loss : 2.8014 - acc : 0.778846\n",
            "60/115 - loss : 2.4945 - acc : 0.746154\n",
            "80/115 - loss : 2.5474 - acc : 0.755769\n",
            "100/115 - loss : 2.7853 - acc : 0.761538\n",
            "====\n",
            "Validation Loss:  2.6704168\n",
            "Validation Acc:  0.7481\n",
            "\n",
            "Epoch 4/10\n",
            "\n",
            "0/115 - loss : 2.2457 - acc : 0.780769\n",
            "20/115 - loss : 2.2563 - acc : 0.767308\n",
            "40/115 - loss : 1.8991 - acc : 0.800000\n",
            "60/115 - loss : 1.8101 - acc : 0.751923\n",
            "80/115 - loss : 1.9978 - acc : 0.761538\n",
            "100/115 - loss : 2.0846 - acc : 0.771154\n",
            "====\n",
            "Validation Loss:  2.0016863\n",
            "Validation Acc:  0.7555\n",
            "\n",
            "Epoch 5/10\n",
            "\n",
            "0/115 - loss : 1.6361 - acc : 0.782692\n",
            "20/115 - loss : 1.7481 - acc : 0.778846\n",
            "40/115 - loss : 1.4046 - acc : 0.796154\n",
            "60/115 - loss : 1.4127 - acc : 0.763462\n",
            "80/115 - loss : 1.6625 - acc : 0.748077\n",
            "100/115 - loss : 1.5550 - acc : 0.775000\n",
            "====\n",
            "Validation Loss:  1.5458912\n",
            "Validation Acc:  0.7665\n",
            "\n",
            "Epoch 6/10\n",
            "\n",
            "0/115 - loss : 1.1920 - acc : 0.788462\n",
            "20/115 - loss : 1.4158 - acc : 0.776923\n",
            "40/115 - loss : 1.1126 - acc : 0.809615\n",
            "60/115 - loss : 1.1304 - acc : 0.776923\n",
            "80/115 - loss : 1.3867 - acc : 0.748077\n",
            "100/115 - loss : 1.1951 - acc : 0.780769\n",
            "====\n",
            "Validation Loss:  1.1864593\n",
            "Validation Acc:  0.7776\n",
            "\n",
            "Epoch 7/10\n",
            "\n",
            "0/115 - loss : 0.9295 - acc : 0.800000\n",
            "20/115 - loss : 1.1002 - acc : 0.790385\n",
            "40/115 - loss : 0.9045 - acc : 0.811538\n",
            "60/115 - loss : 0.8998 - acc : 0.773077\n",
            "80/115 - loss : 1.0628 - acc : 0.763462\n",
            "100/115 - loss : 0.9333 - acc : 0.771154\n",
            "====\n",
            "Validation Loss:  0.9273714\n",
            "Validation Acc:  0.7902\n",
            "\n",
            "Epoch 8/10\n",
            "\n",
            "0/115 - loss : 0.7628 - acc : 0.823077\n",
            "20/115 - loss : 0.8665 - acc : 0.807692\n",
            "40/115 - loss : 0.7219 - acc : 0.821154\n",
            "60/115 - loss : 0.7262 - acc : 0.782692\n",
            "80/115 - loss : 0.8433 - acc : 0.784615\n",
            "100/115 - loss : 0.7822 - acc : 0.792308\n",
            "====\n",
            "Validation Loss:  0.7550671\n",
            "Validation Acc:  0.7979\n",
            "\n",
            "Epoch 9/10\n",
            "\n",
            "0/115 - loss : 0.6581 - acc : 0.828846\n",
            "20/115 - loss : 0.7168 - acc : 0.813462\n",
            "40/115 - loss : 0.5860 - acc : 0.823077\n",
            "60/115 - loss : 0.6109 - acc : 0.790385\n",
            "80/115 - loss : 0.7094 - acc : 0.776923\n",
            "100/115 - loss : 0.6812 - acc : 0.809615\n",
            "====\n",
            "Validation Loss:  0.6489256\n",
            "Validation Acc:  0.8091\n",
            "\n",
            "Epoch 10/10\n",
            "\n",
            "0/115 - loss : 0.5710 - acc : 0.838462\n",
            "20/115 - loss : 0.6218 - acc : 0.821154\n",
            "40/115 - loss : 0.4926 - acc : 0.821154\n",
            "60/115 - loss : 0.5305 - acc : 0.813462\n",
            "80/115 - loss : 0.6147 - acc : 0.809615\n",
            "100/115 - loss : 0.6169 - acc : 0.834615\n",
            "====\n",
            "Validation Loss:  0.58379495\n",
            "Validation Acc:  0.8164\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gZZo6RyVDrN"
      },
      "source": [
        "**Diatas saya menjalankan training pada model sebanyak 10 epoch dengan batchsize sebesar 520 dan juga dengan iterasi sebesar 115 untuk setiap epochnya. Lalu untuk setiap selesai 1 epoch maka program atau model akan mengeluarkan Validation loss atau validasi errornya beserta dengan validasi accuracy atau akurasi akhirnya. Sedangkan untuk setiap 20 epoch model akan mengeluarkan loss atau error dan juga akurasi yang didapat saat itu.**"
      ]
    }
  ]
}